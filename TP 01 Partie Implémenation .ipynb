{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749024f8",
   "metadata": {},
   "source": [
    "<h1 style=\"padding: 8px;color:white; display:fill;background-color:#4683B7; border-radius:6px; font-size:300%\"><b> Introduction aux réseaux de neurones</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb802a",
   "metadata": {},
   "source": [
    "### Réalisé par : GHALIM Nidal | HAMID Hajar | LAHOUIRI Hayat | NACIRI Nacira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a66f32",
   "metadata": {},
   "source": [
    "### Encadré par : Mr KHALFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77e22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibliothèques\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bfef3",
   "metadata": {},
   "source": [
    "### 2.1 Forward et backward manuels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d663b47",
   "metadata": {},
   "source": [
    "### La fonction init_params(nx, nh, ny) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474dfe1",
   "metadata": {},
   "source": [
    "La fonction init_params initialise les poids (Wx et Wy) et les biais bx et by) d'un réseau de neurones à l'aide d'une distribution normale avec une moyenne de zéro et un écart-type de 0.3.\n",
    "\n",
    "Les poids sont initialisés avec des valeurs aléatoires, tandis que les biais sont initialisés à zéro. Les paramètres sont stockés dans un dictionnaire params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc239ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(nx, nh, ny):\n",
    "    # Initialisation des paramètres du réseau de neurones\n",
    "\n",
    "    # Initialisation des poids de la couche d'entrée vers la couche cachée (Wx)\n",
    "    Wx = torch.randn(nh, nx) * 0.3\n",
    "    # Initialisation des biais de la couche cachée (bx)\n",
    "    bx = torch.zeros(nh, 1)\n",
    "    # Initialisation des poids de la couche cachée vers la couche de sortie (Wy)\n",
    "    Wy = torch.randn(ny, nh) * 0.3\n",
    "    # Initialisation des biais de la couche de sortie (by)\n",
    "    by = torch.zeros(ny, 1)\n",
    "    # Stockage des poids et des biais dans un dictionnaire params\n",
    "    params = {\n",
    "        'Wx': Wx,\n",
    "        'bx': bx,\n",
    "        'Wy': Wy,\n",
    "        'by': by\n",
    "    }\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6a2b3",
   "metadata": {},
   "source": [
    "### La fonction forward(params, X) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16adae87",
   "metadata": {},
   "source": [
    "Cette fonction forward effectue la propagation avant dans un réseau de neurones en calculant les étapes intermédiaires telles que les activations de la couche d'entrée (Zx) et de la couche cachée (Ax) en utilisant la fonction tangente hyperbolique (tanh). \n",
    "\n",
    "Ensuite, elle calcule l'activation de la couche de sortie (Zy) et la sortie prédite (Yhat) en appliquant une fonction softmax pour la classification. Les résultats intermédiaires sont stockés dans un dictionnaire outputs, et la fonction renvoie à la fois ces étapes intermédiaires et la prédiction finale du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "291492a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(params, X):\n",
    "    # Initialisation d'un dictionnaire pour stocker les étapes intermédiaires\n",
    "    outputs = {}\n",
    "\n",
    "    # Calcul de l'activation de la couche d'entrée (Zx)\n",
    "    outputs['Zx'] = torch.mm(params['Wx'], X) + params['bx']\n",
    "\n",
    "    # Application de la fonction d'activation tanh pour la couche d'entrée (Ax)\n",
    "    outputs['Ax'] = torch.tanh(outputs['Zx'])\n",
    "\n",
    "    # Calcul de l'activation de la couche de sortie (Zy)\n",
    "    outputs['Zy'] = torch.mm(params['Wy'], outputs['Ax']) + params['by']\n",
    "\n",
    "    # Calcul de la sortie du réseau (Yhat) en appliquant une fonction softmax\n",
    "    outputs['Yhat'] = torch.exp(outputs['Zy']) / torch.sum(torch.exp(outputs['Zy']), dim=0, keepdim=True)\n",
    "\n",
    "    # Retourne à la fois les étapes intermédiaires et la sortie prédite (Yhat)\n",
    "    return outputs, outputs['Yhat']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c306d7a",
   "metadata": {},
   "source": [
    "### La fonction loss_accuracy(Yhat, Y) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44973790",
   "metadata": {},
   "source": [
    "La fonction loss_accuracy calcule à la fois la perte (loss) et la précision (taux de bonnes prédictions) d'un modèle de classification par rapport aux étiquettes réelles.  \n",
    "\n",
    "Elle calcule la perte en utilisant l'entropie croisée moyenne entre les prédictions du modèle (Yhat) et les étiquettes réelles (Y).\n",
    "\n",
    "Ensuite, elle détermine l'indice de la classe réelle pour chaque exemple dans Y et l'indice de la classe prédite pour chaque exemple dans Yhat.\n",
    "\n",
    "La précision est calculée en comparant les indices réels et prédits, puis en comptant combien d'entre eux sont identiques.\n",
    "\n",
    "La fonction retourne à la fois la perte (L), qui mesure la qualité des prédictions du modèle, et la précision (acc), qui indique le pourcentage d'exemples correctement classés par le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edb71a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy(Yhat, Y):\n",
    "    \"\"\" Calcul de la perte (loss) en utilisant l'entropie croisée moyenne\n",
    "     Applique la fonction log à Yhat, puis multiplie élément par élément avec Y,\n",
    "     somme les colonnes (dim=0) pour obtenir la perte pour chaque exemple,\n",
    "     et calcule la moyenne de ces pertes.\"\"\"\n",
    "    L = -torch.mean(torch.sum(Y * torch.log(Yhat), dim=0, keepdim=True))\n",
    "\n",
    "    # Trouve l'indice de la classe réelle pour chaque exemple dans Y\n",
    "    _, indsY = torch.max(Y, 1)\n",
    "    # Trouve l'indice de la classe prédite pour chaque exemple dans Yhat\n",
    "    _, indsYhat = torch.max(Yhat, 1)\n",
    "    # Calcule la précision en comparant les indices réels et prédits,\n",
    "    # compte combien d'entre eux sont identiques, puis divise par le nombre d'exemples.\n",
    "    acc = torch.sum(indsY == indsYhat) / Y.shape[1]\n",
    "\n",
    "    # Retourne la perte (L) et la précision (acc)\n",
    "    return L, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544914e1",
   "metadata": {},
   "source": [
    "### La fonction backward(params, outputs, Y) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf21f43",
   "metadata": {},
   "source": [
    "La fonction backward calcule les gradients des paramètres du réseau en utilisant la rétropropagation.Elle prend en entrée trois arguments : params (un dictionnaire contenant les paramètres du réseau, tels que les poids et les biais), outputs (un dictionnaire contenant les sorties intermédiaires du réseau calculées lors de la propagation avant) et Y (les étiquettes réelles).\n",
    "\n",
    "Elle commence par calculer le gradient de la couche de sortie (dZy), qui mesure comment la perte varie en fonction des sorties de la couche de sortie.\n",
    "\n",
    "Ensuite, elle calcule le gradient de la perte par rapport aux poids et aux biais de la couche de sortie (dWy et dby) en utilisant dZy.\n",
    "\n",
    "Elle continue la rétropropagation en calculant le gradient de la couche cachée par rapport à ses entrées pondérées (dZx) en utilisant la dérivée de la fonction d'activation tangente hyperbolique (tanh).\n",
    "\n",
    "Puis, elle calcule les gradients des poids et des biais de la couche d'entrée (dWx et dbx) en utilisant dZx.\n",
    "\n",
    "Les gradients calculés sont retournés dans un dictionnaire grads, qui peut ensuite être utilisé pour mettre à jour les paramètres du réseau lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0620b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(params, outputs, Y):\n",
    "    grads = {}\n",
    "\n",
    "    # Calcul du gradient de la couche de sortie (dZy)\n",
    "    grads['dZy'] = outputs['Yhat'] - Y\n",
    "\n",
    "    # Calcul du gradient de la couche de sortie par rapport à Wy (dWy)\n",
    "    grads['dWy'] = torch.mm(grads['dZy'], outputs['Ax'].t()) / Y.shape[1]\n",
    "\n",
    "    # Calcul du gradient de la couche de sortie par rapport à by (dby)\n",
    "    grads['dby'] = torch.sum(grads['dZy'], dim=1, keepdim=True) / Y.shape[1]\n",
    "\n",
    "    # Calcul du gradient de la couche cachée par rapport à Zx (dAx)\n",
    "    grads['dAx'] = torch.mm(params['Wy'].t(), grads['dZy'])\n",
    "\n",
    "    # Calcul du gradient de la couche cachée par rapport à Zx (dZx)\n",
    "    grads['dZx'] = grads['dAx'] * (1 - outputs['Ax'] ** 2)  # Dérivée de tanh\n",
    "\n",
    "    # Calcul du gradient de la couche cachée par rapport à Wx (dWx)\n",
    "    grads['dWx'] = torch.mm(grads['dZx'], outputs['X'].t()) / Y.shape[1]\n",
    "\n",
    "    # Calcul du gradient de la couche cachée par rapport à bx (dbx)\n",
    "    grads['dbx'] = torch.sum(grads['dZx'], dim=1, keepdim=True) / Y.shape[1]\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73dff65",
   "metadata": {},
   "source": [
    "### La fonction sgd(params, grads, eta) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d125e6",
   "metadata": {},
   "source": [
    "La fonction sgd est une implémentation de la descente de gradient stochastique (SGD), un algorithme d'optimisation couramment utilisé pour entraîner des réseaux de neurones. \n",
    "\n",
    "Elle prend en entrée trois paramètres : params (un dictionnaire de paramètres du réseau, tels que les poids et les biais), grads (un dictionnaire de gradients par rapport à ces paramètres) et eta (le taux d'apprentissage).\n",
    "\n",
    "Notre fonction itère à travers chaque paramètre du réseau.\n",
    "\n",
    "Pour chaque paramètre, elle met à jour sa valeur en soustrayant le produit du taux d'apprentissage (eta) et du gradient correspondant. Cette mise à jour permet d'ajuster les paramètres du réseau dans la direction qui minimise la perte.\n",
    "\n",
    "La descente de gradient stochastique est utilisée pour ajuster progressivement les paramètres du réseau afin d'optimiser la fonction de coût, ce qui conduit à des prédictions plus précises.\n",
    "\n",
    "En résultat, la fonction sgd met à jour les paramètres du réseau en fonction des gradients calculés, ce qui est essentiel pour l'apprentissage supervisé et l'amélioration des performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83114c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, grads, eta):\n",
    "    # Pour chaque paramètre du réseau\n",
    "    for param_name in params:\n",
    "        # Mettre à jour le paramètre en soustrayant le produit du taux d'apprentissage (eta) et du gradient correspondant\n",
    "        params[param_name] -= eta * grads[param_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f2ecf",
   "metadata": {},
   "source": [
    "### L’algorithme global :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939d0d1",
   "metadata": {},
   "source": [
    "Cet algorithme qu'on a généré commence par charger ou préparer les données, initialiser les paramètres du réseau de neurones, et créer une liste pour stocker les performances du modèle. \n",
    "\n",
    "Ensuite, il effectue un certain nombre d'époques d'apprentissage, où chaque époque consiste en une itération sur les mini-batchs des données d'entraînement. À chaque itération, l'algorithme effectue un passage en avant (forward) pour calculer la perte, puis réalise la rétropropagation (backward) pour calculer les gradients et ajuster les paramètres du modèle à l'aide de la descente de gradient stochastique. Les performances du modèle sont calculées sur les données d'entraînement et de test à chaque époque, et les résultats sont affichés. \n",
    "\n",
    "Enfin, les courbes d'apprentissage sont générées pour visualiser l'évolution de la précision et de la perte au cours de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et préparer les données avant d'appliquer l'algorithme\n",
    "\n",
    "# Initialisation des paramètres du réseau\n",
    "params = init_params(nx, nh, ny)\n",
    "\n",
    "# Liste pour stocker les performances (précision et perte) au fil de l'apprentissage\n",
    "performance_metrics = [[], [], [], []]\n",
    "\n",
    "# Boucle sur les époques d'apprentissage\n",
    "for epoch in range(150):\n",
    "\n",
    "    # Permutation des données (remplacer par le chargement de données)\n",
    "    # Exemple : perm = np.random.permutation(N)\n",
    "    # Xtrain = Xtrain[perm, :]\n",
    "    # Ytrain = Ytrain[perm, :]\n",
    "\n",
    "    # Itération sur les mini-batchs\n",
    "    for j in range(N // Nbatch):\n",
    "        batch_indices = range(j * Nbatch, (j+1) * Nbatch)\n",
    "        X_batch = Xtrain[batch_indices, :]\n",
    "        Y_batch = Ytrain[batch_indices, :]\n",
    "\n",
    "        # Passage en avant (forward), calcul de la perte et rétropropagation (backward)\n",
    "        outputs, Yhat = forward(params, X_batch)\n",
    "        loss, _ = loss_accuracy(Yhat, Y_batch)\n",
    "        gradients = backward(params, outputs, Y_batch)\n",
    "        sgd(params, gradients, eta)\n",
    "\n",
    "    # Passage en avant sur les données d'entraînement, de test et calcul des performances\n",
    "    Yhat_train, _ = forward(params, Xtrain)\n",
    "    Yhat_test, _ = forward(params, Xtest)\n",
    "    train_loss, train_accuracy = loss_accuracy(Yhat_train, Ytrain)\n",
    "    test_loss, test_accuracy = loss_accuracy(Yhat_test, Ytest)\n",
    "\n",
    "    # Affichage des performances\n",
    "    title = f'Epoch {epoch}: Train Accuracy {train_accuracy:.1f}% (Loss {train_loss:.2f}), Test Accuracy {test_accuracy:.1f}% (Loss {test_loss:.2f})'\n",
    "    print(title)\n",
    "\n",
    "    # Ajout des performances à la liste\n",
    "    performance_metrics[0].append(train_accuracy)\n",
    "    performance_metrics[1].append(test_accuracy)\n",
    "    performance_metrics[2].append(train_loss)\n",
    "    performance_metrics[3].append(test_loss)\n",
    "\n",
    "# Affichage des courbes d'apprentissage\n",
    "fig = plt.figure()\n",
    "plt.plot(performance_metrics[0], label=\"Train Accuracy\")\n",
    "plt.plot(performance_metrics[1], label=\"Test Accuracy\")\n",
    "plt.plot(performance_metrics[2], label=\"Train Loss\")\n",
    "plt.plot(performance_metrics[3], label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808ef71",
   "metadata": {},
   "source": [
    "# 2.2 Simplification du backward avec torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c5e0f",
   "metadata": {},
   "source": [
    "#### 1. Activation d'autograd sur les poids du réseau :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba51bc41",
   "metadata": {},
   "source": [
    "autograd (\"automatic differentiation\") est une composante essentielle de PyTorch qui permet le calcul automatique des gradients. \n",
    "\n",
    "Il s'agit d'un système de différenciation automatique qui est utilisé pour calculer les dérivées des opérations effectuées sur les tenseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0441c",
   "metadata": {},
   "source": [
    "La fontion Formward et la fonction loss_accuracy restent les mêmes, elle est inchangée par rapport à la précédente.\n",
    "Ausi, on aura pas de fonction backward à cause de l'autograd.\n",
    "Voici les 2 changements qu'on va avoir pour notre fonctions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29eb51",
   "metadata": {},
   "source": [
    "### La nouvelle fonction init_params(nx, nh, ny) pour Simplification du backward avec torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c4f0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(nx, nh, ny):\n",
    "    # Initialisation des paramètres du réseau de neurones\n",
    "\n",
    "    # Initialisation des poids de la couche d'entrée vers la couche cachée (Wx) avec autograd activé\n",
    "    Wx = torch.randn(nh, nx, requires_grad=True) * 0.3\n",
    "    # Initialisation des biais de la couche cachée (bx) avec autograd activé\n",
    "    bx = torch.zeros(nh, 1, requires_grad=True)\n",
    "    # Initialisation des poids de la couche cachée vers la couche de sortie (Wy) avec autograd activé\n",
    "    Wy = torch.randn(ny, nh, requires_grad=True) * 0.3\n",
    "    # Initialisation des biais de la couche de sortie (by) avec autograd activé\n",
    "    by = torch.zeros(ny, 1, requires_grad=True)\n",
    "    # Stockage des poids et des biais dans un dictionnaire params\n",
    "    params = {\n",
    "        'Wx': Wx,\n",
    "        'bx': bx,\n",
    "        'Wy': Wy,\n",
    "        'by': by\n",
    "    }\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74366b-67da-4f2f-a72e-4b6d917aef15",
   "metadata": {},
   "source": [
    "### La nouvelle fonction sgd(params, eta)  pour Simplification du backward avec torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8535e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, eta):\n",
    "    # Mettre à jour les poids en utilisant les gradients calculés avec autograd\n",
    "    with torch.no_grad():\n",
    "        params[\"Wh\"] -= eta * params[\"Wh\"].grad\n",
    "        params[\"Wy\"] -= eta * params[\"Wy\"].grad\n",
    "        params[\"bh\"] -= eta * params[\"bh\"].grad\n",
    "        params[\"by\"] -= eta * params[\"by\"].grad\n",
    "\n",
    "        # Remettre les accumulateurs de gradient à zéro\n",
    "        params[\"Wh\"].grad.zero_()\n",
    "        params[\"Wy\"].grad.zero_()\n",
    "        params[\"bh\"].grad.zero_()\n",
    "        params[\"by\"].grad.zero_()\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15103fda",
   "metadata": {},
   "source": [
    "### Algorithme global d'apprentissage avec autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et préparer les données ici\n",
    "\n",
    "# Initialisation des paramètres du réseau\n",
    "params = init_params(nx, nh, ny)\n",
    "\n",
    "# Liste pour stocker les performances (précision et perte) au fil de l'apprentissage\n",
    "performance_metrics = [[], [], [], []]\n",
    "\n",
    "# Boucle sur les époques d'apprentissage\n",
    "for epoch in range(150):\n",
    "\n",
    "    # Permutation des données (remplacer par le chargement de données)\n",
    "    # Exemple : perm = np.random.permutation(N)\n",
    "    # Xtrain = Xtrain[perm, :]\n",
    "    # Ytrain = Ytrain[perm, :]\n",
    "\n",
    "    # Itération sur les mini-batchs\n",
    "    for j in range(N // Nbatch):\n",
    "        batch_indices = range(j * Nbatch, (j+1) * Nbatch)\n",
    "        X_batch = Xtrain[batch_indices, :]\n",
    "        Y_batch = Ytrain[batch_indices, :]\n",
    "\n",
    "        # Passage en avant (forward), calcul de la perte et rétropropagation (backward) avec autograd\n",
    "        outputs, Yhat = forward(params, X_batch)\n",
    "        loss, _ = loss_accuracy(Yhat, Y_batch)\n",
    "        loss.backward()  # Calcule automatiquement les gradients\n",
    "\n",
    "        # Utilisation des gradients pour mettre à jour les paramètres avec SGD\n",
    "        sgd(params, eta)\n",
    "\n",
    "    # Passage en avant sur les données d'entraînement, de test et calcul des performances\n",
    "    Yhat_train, _ = forward(params, Xtrain)\n",
    "    Yhat_test, _ = forward(params, Xtest)\n",
    "    train_loss, train_accuracy = loss_accuracy(Yhat_train, Ytrain)\n",
    "    test_loss, test_accuracy = loss_accuracy(Yhat_test, Ytest)\n",
    "\n",
    "    # Affichage des performances\n",
    "    title = f'Epoch {epoch}: Train Accuracy {train_accuracy:.1f}% (Loss {train_loss:.2f}), Test Accuracy {test_accuracy:.1f}% (Loss {test_loss:.2f})'\n",
    "    print(title)\n",
    "\n",
    "    # Ajout des performances à la liste\n",
    "    performance_metrics[0].append(train_accuracy)\n",
    "    performance_metrics[1].append(test_accuracy)\n",
    "    performance_metrics[2].append(train_loss)\n",
    "    performance_metrics[3].append(test_loss)\n",
    "\n",
    "# Affichage des courbes d'apprentissage\n",
    "fig = plt.figure()\n",
    "plt.plot(performance_metrics[0], label=\"Train Accuracy\")\n",
    "plt.plot(performance_metrics[1], label=\"Test Accuracy\")\n",
    "plt.plot(performance_metrics[2], label=\"Train Loss\")\n",
    "plt.plot(performance_metrics[3], label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19776cb2",
   "metadata": {},
   "source": [
    "# 2.3 Simplification du forward avec les couches torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e70523",
   "metadata": {},
   "source": [
    "torch.nn est un module de PyTorch qui fournit des classes et des fonctions pour la création et la gestion de réseaux de neurones artificiels. \n",
    "\n",
    "Il s'agit d'une partie essentielle de PyTorch pour le développement de modèles d'apprentissage profond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f69be7",
   "metadata": {},
   "source": [
    "Les fonctions init_params et forward seront supprimés et remplacés par une fonction init_model qui déclare l'architecture du modèle et la loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba7dad",
   "metadata": {},
   "source": [
    "### La nouvelle fonction init_model(nx, nh, ny):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0831181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_model(nx, nh, ny):\n",
    "    # Déclaration de l'architecture du modèle\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(nx, nh),    # Couche linéaire de la couche d'entrée à la couche cachée\n",
    "        nn.Tanh(),           # Fonction d'activation Tanh après la première couche\n",
    "        nn.Linear(nh, ny),    # Couche linéaire de la couche cachée à la couche de sortie\n",
    "        nn.Softmax(dim=0)     # Fonction Softmax appliquée à la sortie\n",
    "    )\n",
    "\n",
    "    # Déclaration de la fonction de perte\n",
    "    loss = nn.CrossEntropyLoss()  # Entropie croisée utilisée comme fonction de perte\n",
    "\n",
    "    return model, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf606b8",
   "metadata": {},
   "source": [
    "### La nouvelle fonction loss_accuracy(model, loss, X, Y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7a8965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_accuracy(model, loss, X, Y):\n",
    "    \"\"\" Calcul de la perte (loss) en utilisant la fonction de perte (CrossEntropyLoss)\n",
    "    Applique la fonction softmax (déjà définie dans le modèle) sur la sortie du modèle, puis calcule la perte.\n",
    "    Retourne la perte (loss) et la précision (acc).\n",
    "    \"\"\"\n",
    "    # Passage avant avec le modèle\n",
    "    Yhat = model(X)\n",
    "\n",
    "    # Calcul de la perte avec la fonction de perte (CrossEntropyLoss)\n",
    "    L = loss(Yhat, Y)\n",
    "\n",
    "    # Trouve l'indice de la classe réelle pour chaque exemple dans Y\n",
    "    _, indsY = torch.max(Y, 1)\n",
    "    # Trouve l'indice de la classe prédite pour chaque exemple dans Yhat\n",
    "    _, indsYhat = torch.max(Yhat, 1)\n",
    "    # Calcule la précision en comparant les indices réels et prédits\n",
    "    acc = torch.sum(indsY == indsYhat).item() / len(Y)\n",
    "\n",
    "    # Retourne la perte (L) et la précision (acc)\n",
    "    return L, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069bfd7",
   "metadata": {},
   "source": [
    "### La nouvelle fonction sgd(params, grads, eta)  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "285a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(model, eta):\n",
    "    # Réinitialiser les gradients du modèle\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Calculer les gradients en fonction de la perte actuelle\n",
    "    loss.backward()\n",
    "\n",
    "    # Mettre à jour les paramètres du modèle\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= eta * param.grad\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22b29d",
   "metadata": {},
   "source": [
    "# 2.4 Simplification de SGD avec torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354866f9",
   "metadata": {},
   "source": [
    "torch.optim est un module de PyTorch qui contient divers optimiseurs couramment utilisés pour l'entraînement de modèles de réseaux de neurones. Ces optimiseurs implémentent différentes variantes de l'algorithme de descente de gradient stochastique (SGD) ainsi que d'autres algorithmes d'optimisation populaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab36d30",
   "metadata": {},
   "source": [
    "La fonction sgd est supprimée.D'où, on fera un appel à optim.zero_grad() avant de faire le backward et à optim.step() après le backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffb944f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(nx, nh, ny, eta):\n",
    "    # Déclaration de l'architecture du modèle\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(nx, nh),    # Couche linéaire de la couche d'entrée à la couche cachée\n",
    "        nn.Tanh(),           # Fonction d'activation Tanh après la première couche\n",
    "        nn.Linear(nh, ny),    # Couche linéaire de la couche cachée à la couche de sortie\n",
    "        nn.Softmax(dim=1)     # Fonction Softmax appliquée à la sortie\n",
    "    )\n",
    "\n",
    "    # Déclaration de la fonction de perte\n",
    "    loss = nn.CrossEntropyLoss()  # Entropie croisée utilisée comme fonction de perte\n",
    "\n",
    "    # Initialisation de l'optimiseur (SGD) avec le taux d'apprentissage (learning rate)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "    return model, loss, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e02ff2",
   "metadata": {},
   "source": [
    "Dans cette version, la fonction init_model nous retourne également l'optimiseur initialisé avec le learning rate eta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20013e49",
   "metadata": {},
   "source": [
    "## Application à MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407005ec",
   "metadata": {},
   "source": [
    "Voici une implémentation d'un réseau de neurones pour la classification des chiffres manuscrits du jeu de données MNIST.\n",
    "\n",
    "La boucle d'entraînement utilise ces composants pour ajuster le modèle aux données d'entraînement, tandis que l'évaluation sur l'ensemble de test est effectuée après chaque époque. Les courbes d'apprentissage, représentant la précision et la perte au fil des époques, sont ensuite affichées pour évaluer la performance du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d5d8aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.1462, Accuracy: 59.23%\n",
      "Epoch 2/5, Loss: 1.8654, Accuracy: 73.35%\n",
      "Epoch 3/5, Loss: 1.7520, Accuracy: 79.54%\n",
      "Epoch 4/5, Loss: 1.7084, Accuracy: 81.16%\n",
      "Epoch 5/5, Loss: 1.6862, Accuracy: 81.72%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fonction pour initialiser le modèle, la perte et l'optimiseur\n",
    "def init_model(nx, nh, ny, eta):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(nx, nh),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(nh, ny),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "    return model, loss_fn, optimizer\n",
    "\n",
    "# Fonction pour calculer la perte et la précision\n",
    "def loss_accuracy(model, loss, X, Y):\n",
    "    Yhat = model(X)\n",
    "    L = loss(Yhat, Y.squeeze().long())  # Squeeze pour enlever la dimension supplémentaire et long() pour convertir en int\n",
    "    _, indsYhat = torch.max(Yhat, 1)\n",
    "    acc = torch.sum(Y.squeeze().long() == indsYhat).item() / len(Y)\n",
    "\n",
    "    return L, acc\n",
    "\n",
    "\n",
    "# Chargement des données MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(mnist_dataset))\n",
    "test_size = len(mnist_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(mnist_dataset, [train_size, test_size])\n",
    "\n",
    "# Chargement des données avec des DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Paramètres d'entraînement\n",
    "nx = 28 * 28  # Dimension de l'image MNIST\n",
    "nh = 100\n",
    "ny = 10  # Nombre de classes dans MNIST (0-9)\n",
    "eta = 0.03\n",
    "\n",
    "# Initialisation du modèle, de la perte et de l'optimiseur\n",
    "model, loss_fn, optimizer = init_model(nx, nh, ny, eta)\n",
    "\n",
    "# Listes pour stocker les courbes d'apprentissage\n",
    "curves = [[], []]\n",
    "\n",
    "# Entraînement\n",
    "for epoch in range(5):  # Choisissez le nombre d'époques souhaité\n",
    "    for batch in train_loader:\n",
    "        X, Y = batch\n",
    "\n",
    "        # Reshape X pour s'adapter au modèle\n",
    "        X = X.view(-1, 28 * 28)\n",
    "\n",
    "        # Forward pass\n",
    "        Yhat = model(X)\n",
    "\n",
    "        # Calcul de la perte et de la précision\n",
    "        loss, _ = loss_accuracy(model, loss_fn, X, Y)\n",
    "\n",
    "        # Rétropropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimisation\n",
    "        optimizer.step()\n",
    "\n",
    "    # Évaluation sur l'ensemble de test après chaque époque\n",
    "    total_loss, total_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X, Y = batch\n",
    "\n",
    "            # Reshape X pour s'adapter au modèle\n",
    "            X = X.view(-1, 28 * 28)\n",
    "\n",
    "            loss, acc = loss_accuracy(model, loss_fn, X, Y)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc = total_acc / len(test_loader)\n",
    "\n",
    "    # Affichage des résultats d'évaluation\n",
    "    print(f'Epoch {epoch+1}/{5}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.2%}')\n",
    "\n",
    "    # Ajout des résultats aux courbes\n",
    "    curves[0].append(avg_acc * 100)\n",
    "    curves[1].append(avg_loss)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.plot(curves[0], label=\"Accuracy\", color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Loss', color=color)\n",
    "ax2.plot(curves[1], label=\"Loss\", color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('MNIST Training Curves')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
